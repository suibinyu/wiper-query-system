import streamlit as st
import pandas as pd
import sqlite3
import os
# éšè—Streamlitçš„é»˜è®¤èœå•å’ŒæŒ‰é’®
hide_streamlit_style = """
    <style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    .stDeployButton {visibility: hidden;}
    </style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)
# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="é›¨åˆ·æŸ¥è¯¢",
    page_icon="ğŸš—",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# éšè—Streamlité»˜è®¤å…ƒç´ 
hide_streamlit_style = """
    <style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    .stDeployButton {display: none;}
    </style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# åˆå§‹åŒ–æ•°æ®åº“
@st.cache_resource
def init_database():
    try:
        if not os.path.exists("wiper_data.xlsx"):
            st.error("æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°")
            return None
        
        df = pd.read_excel("wiper_data.xlsx")
        conn = sqlite3.connect('wiper_system.db', check_same_thread=False)
        df.to_sql('wiper_specs', conn, if_exists='replace', index=False)
        return conn
    except Exception as e:
        st.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
        return None

# ç®€åŒ–çš„æŸ¥è¯¢å‡½æ•° - åªæœç´¢è½¦å‹å­—æ®µ
def search_wiper_specs(conn, search_term):
    try:
        cursor = conn.cursor()
        cursor.execute("PRAGMA table_info(wiper_specs)")
        columns = [col[1] for col in cursor.fetchall()]
        
        # åªæœç´¢è½¦å‹å­—æ®µ
        if 'è½¦å‹' in columns:
            query = "SELECT * FROM wiper_specs WHERE è½¦å‹ LIKE ? ORDER BY å“ç‰Œ, å¹´ä»½ DESC"
        else:
            query = "SELECT * FROM wiper_specs WHERE model LIKE ? ORDER BY brand, year DESC"
        
        search_pattern = f"%{search_term}%"
        df_result = pd.read_sql_query(query, conn, params=[search_pattern])
        return df_result
        
    except Exception as e:
        st.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
        return pd.DataFrame()

# ä¸»é¡µé¢
def main():
    # ç®€æ´æ ‡é¢˜
    st.markdown("<h2 style='text-align: center;'>ğŸš— é›¨åˆ·æŸ¥è¯¢</h2>", unsafe_allow_html=True)
    
    # æœç´¢æ¡†
    search_term = st.text_input("", placeholder="è¾“å…¥è½¦å‹åç§°ï¼Œå¦‚ï¼šé«˜å°”å¤«")
    
    # æœç´¢æŒ‰é’®
    if st.button("æŸ¥è¯¢", use_container_width=True):
        conn = init_database()
        if conn and search_term:
            # æå–çº¯è½¦å‹å…³é”®è¯ï¼ˆç§»é™¤å“ç‰Œä¿¡æ¯ï¼‰
            clean_search_term = extract_model_keyword(search_term)
            results = search_wiper_specs(conn, clean_search_term)
            display_results(results, clean_search_term)
        elif not search_term:
            st.warning("è¯·è¾“å…¥è½¦å‹åç§°")
        else:
            st.error("ç³»ç»Ÿæš‚ä¸å¯ç”¨")

# æå–çº¯è½¦å‹å…³é”®è¯çš„å‡½æ•°
def extract_model_keyword(search_term):
    """ä»æœç´¢è¯ä¸­æå–çº¯è½¦å‹å…³é”®è¯"""
    # å¸¸è§çš„æ±½è½¦å“ç‰Œåˆ—è¡¨
    common_brands = [
        'å¤§ä¼—', 'ä¸°ç”°', 'æœ¬ç”°', 'æ—¥äº§', 'å®é©¬', 'å¥”é©°', 'å¥¥è¿ª', 'ç°ä»£', 
        'èµ·äºš', 'ç¦ç‰¹', 'é›ªä½›å…°', 'åˆ«å…‹', 'æ ‡è‡´', 'é›ªé“é¾™', 'é©¬è‡ªè¾¾',
        'æ–¯å·´é²', 'ä¸‰è±', 'é“ƒæœ¨', 'æ²ƒå°”æ²ƒ', 'é›·å…‹è¨æ–¯', 'è‹±è²å°¼è¿ª',
        'è®´æ­Œ', 'å‡¯è¿ªæ‹‰å…‹', 'æ—è‚¯', 'æ·è±¹', 'è·¯è™', 'ä¿æ—¶æ·', 'æ³•æ‹‰åˆ©',
        'å…°åšåŸºå°¼', 'ç›èæ‹‰è’‚', 'ç‰¹æ–¯æ‹‰', 'è”šæ¥', 'ç†æƒ³', 'å°é¹', 'æ¯”äºšè¿ª'
    ]
    
    # ç§»é™¤å“ç‰Œä¿¡æ¯
    clean_term = search_term
    for brand in common_brands:
        if brand in clean_term:
            clean_term = clean_term.replace(brand, '')
    
    # ç§»é™¤å¯èƒ½çš„å¤šä½™ç©ºæ ¼å’Œç¬¦å·
    clean_term = clean_term.strip().replace(' ', '').replace('Â·', '')
    
    # å¦‚æœç§»é™¤å“ç‰Œåä¸ºç©ºï¼Œåˆ™ä½¿ç”¨åŸè¯
    if not clean_term:
        return search_term
    
    return clean_term

# ç®€æ´ç»“æœæ˜¾ç¤º
def display_results(df, search_term):
    if df.empty:
        st.info(f"æœªæ‰¾åˆ°ã€{search_term}ã€ç›¸å…³è®°å½•")
        st.markdown("""
        ğŸ’¡ **æœç´¢æç¤º**ï¼š
        - è¯·è¾“å…¥è½¦å‹åç§°ï¼Œå¦‚ï¼š"é«˜å°”å¤«"
        - æ”¯æŒæ¨¡ç³Šæœç´¢ï¼Œè¾“å…¥"é«˜å°”"ä¹Ÿèƒ½æ‰¾åˆ°é«˜å°”å¤«
        """)
        return
    
    st.success(f"æ‰¾åˆ° {len(df)} æ¡è®°å½•")
    
    for idx, row in df.iterrows():
        # è·å–æ•°æ® - ä½¿ç”¨æ–°çš„åˆ—å
        brand = row.get('å“ç‰Œ', '')
        model = row.get('è½¦å‹', '')
        year = row.get('å¹´ä»½', '')
        
        front_driver = row.get('ä¸»é©¾', '')
        front_passenger = row.get('å‰¯é©¾', '')
        connector = row.get('æ¥å¤´', '')
        rear = row.get('åé›¨åˆ·', '')
        note = row.get('å¤‡æ³¨', '')
        
        # ç´§å‡‘æ˜¾ç¤º
        st.markdown(f"**{brand} {model}** Â· {year}æ¬¾")
        
        specs = []
        if front_driver and front_passenger:
            specs.append(f"ä¸»é©¾: {front_driver}â€³")
            specs.append(f"å‰¯é©¾: {front_passenger}â€³")
        elif front_driver:
            specs.append(f"é›¨åˆ·: {front_driver}â€³")
        
        # æ¥å¤´ä¿¡æ¯æ’åœ¨å‰é¢
        if connector and str(connector) != 'nan':
            specs.append(f"æ¥å¤´: {connector}")
        
        # åé›¨åˆ·ä¿¡æ¯æ’åœ¨åé¢
        if rear and str(rear) != 'nan':
            specs.append(f"åé›¨åˆ·: {rear}â€³")
        
        if specs:
            st.markdown(f"<small>{' | '.join(specs)}</small>", unsafe_allow_html=True)
        
        # æ˜¾ç¤ºå¤‡æ³¨ä¿¡æ¯
        if note and str(note) != 'nan' and str(note) != '':
            st.markdown(f"<small>ğŸ“ {note}</small>", unsafe_allow_html=True)
        
        st.markdown("---")

if __name__ == "__main__":
    main()

