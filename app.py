import streamlit as st
import pandas as pd

# é¡µé¢è®¾ç½®
st.set_page_config(
    page_title="é›¨åˆ·å°ºå¯¸æŸ¥è¯¢ç³»ç»Ÿ",
    page_icon="ğŸŒ§ï¸",
    layout="centered"
)

# åº”ç”¨æ ‡é¢˜
st.title("ğŸŒ§ï¸ æ±½è½¦é›¨åˆ·å°ºå¯¸æŸ¥è¯¢ç³»ç»Ÿ")
st.markdown("è¾“å…¥æ‚¨çš„è½¦å‹åç§°ï¼ŒæŸ¥è¯¢å¯¹åº”çš„é›¨åˆ·å°ºå¯¸å’Œæ¥å¤´ç±»å‹")

# åŠ è½½Excelæ•°æ®
@st.cache_data
def load_excel_data():
    try:
        # è¯»å–æ•°æ®
        wiper_data = pd.read_excel('data/wiper_data.xlsx', sheet_name='wiper_data')
        return wiper_data
    except FileNotFoundError:
        st.error("æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·ç¡®ä¿ data/wiper_data.xlsx æ–‡ä»¶å­˜åœ¨")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"è¯»å–æ•°æ®æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return pd.DataFrame()

# åŠ è½½æ•°æ®
wiper_data = load_excel_data()

if wiper_data.empty:
    st.stop()

# æœç´¢æ¡†
st.markdown("### ğŸ” è¾“å…¥è½¦å‹åç§°æœç´¢")
search_term = st.text_input(
    "è¯·è¾“å…¥è½¦å‹åç§°ï¼ˆä¾‹å¦‚ï¼šå¡ç½—æ‹‰ã€CR-Vã€3ç³»ç­‰ï¼‰", 
    placeholder="è¾“å…¥è½¦å‹åç§°...",
    key="search_input"
)

# æ˜¾ç¤ºæœç´¢ç»“æœ
if search_term:
    # æœç´¢é€»è¾‘ï¼šåœ¨è½¦å‹åˆ—ä¸­æŸ¥æ‰¾åŒ…å«æœç´¢è¯çš„è¡Œï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    search_results = wiper_data[
        wiper_data['è½¦å‹'].str.contains(search_term, case=False, na=False)
    ]
    
    if not search_results.empty:
        st.success(f"âœ… æ‰¾åˆ° {len(search_results)} ä¸ªåŒ¹é…è½¦å‹")
        
        # æ˜¾ç¤ºæ¯ä¸ªåŒ¹é…çš„ç»“æœ
        for idx, result in search_results.iterrows():
            with st.container():
                st.markdown("---")
                col1, col2 = st.columns([1, 2])
                
                with col1:
                    st.subheader(f"{result['å“ç‰Œ']} {result['è½¦å‹']}")
                    st.caption(f"å¹´ä»½: {result['å¹´ä»½']}")
                
                with col2:
                    col2_1, col2_2, col2_3 = st.columns(3)
                    
                    with col2_1:
                        st.metric("ä¸»é©¾å°ºå¯¸", f"{result['ä¸»é©¾é›¨åˆ·å°ºå¯¸(å¯¸)']}å¯¸")
                    
                    with col2_2:
                        st.metric("å‰¯é©¾å°ºå¯¸", f"{result['å‰¯é©¾é›¨åˆ·å°ºå¯¸(å¯¸)']}å¯¸")
                    
                    with col2_3:
                        st.metric("æ¥å¤´ç±»å‹", result['ä¸»é©¾æ¥å¤´ç±»å‹'])
                
                # æ˜¾ç¤ºå¤‡æ³¨ï¼ˆå¦‚æœæœ‰ï¼‰
                if pd.notna(result['å¤‡æ³¨']) and result['å¤‡æ³¨'] != '':
                    st.info(f"å¤‡æ³¨: {result['å¤‡æ³¨']}")
        
        # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼ï¼ˆå¯é€‰ï¼‰
        with st.expander("ğŸ“‹ æŸ¥çœ‹è¯¦ç»†æ•°æ®è¡¨æ ¼"):
            display_columns = ['å“ç‰Œ', 'è½¦å‹', 'å¹´ä»½', 'ä¸»é©¾é›¨åˆ·å°ºå¯¸(å¯¸)', 'å‰¯é©¾é›¨åˆ·å°ºå¯¸(å¯¸)', 'ä¸»é©¾æ¥å¤´ç±»å‹', 'å‰¯é©¾æ¥å¤´ç±»å‹']
            st.dataframe(
                search_results[display_columns],
                use_container_width=True,
                hide_index=True
            )
    else:
        st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„è½¦å‹ï¼Œè¯·å°è¯•ä»¥ä¸‹å»ºè®®ï¼š")
        st.markdown("""
        - æ£€æŸ¥æ‹¼å†™æ˜¯å¦æ­£ç¡®
        - å°è¯•ä½¿ç”¨æ›´é€šç”¨çš„è½¦å‹åç§°ï¼ˆå¦‚åªè¾“å…¥'å¡ç½—'è€Œä¸æ˜¯'å¡ç½—æ‹‰'ï¼‰
        - æˆ–æµè§ˆä¸‹é¢çš„çƒ­é—¨è½¦å‹
        """)

# çƒ­é—¨è½¦å‹æ¨èï¼ˆå½“æ²¡æœ‰æœç´¢æˆ–æœç´¢æ— ç»“æœæ—¶æ˜¾ç¤ºï¼‰
if not search_term or (search_term and search_results.empty):
    st.markdown("### ğŸš— çƒ­é—¨è½¦å‹å‚è€ƒ")
    
    # æ˜¾ç¤ºä¸€äº›çƒ­é—¨è½¦å‹ä½œä¸ºå‚è€ƒ
    popular_models = wiper_data.head(8)  # æ˜¾ç¤ºå‰8ä¸ªè½¦å‹ä½œä¸ºçƒ­é—¨å‚è€ƒ
    
    cols = st.columns(4)
    for idx, (col, model) in enumerate(zip(cols, popular_models.iterrows())):
        _, model_data = model
        with col:
            st.button(
                f"{model_data['å“ç‰Œ']} {model_data['è½¦å‹']}",
                key=f"model_{idx}",
                use_container_width=True,
                on_click=lambda x=model_data['è½¦å‹']: st.session_state.update({"search_input": x})
            )

# æ¥å¤´ç±»å‹è¯´æ˜
st.markdown("---")
st.markdown("### ğŸ’¡ æ¥å¤´ç±»å‹è¯´æ˜")

connector_info = {
    "Uå‹": "ä¼ ç»Ÿçš„Uå‹æŒ‚é’©ï¼Œå®‰è£…ç®€å•ï¼Œé€‚ç”¨äºå¤§å¤šæ•°ç»æµå‹è½¦å‹",
    "ç›´æ’å¼": "ç›´æ¥æ’å…¥çš„æ¥å¤´ï¼Œå¸¸è§äºæ—¥ç³»å’Œéƒ¨åˆ†å›½äº§è½¦å‹",
    "å‹¾å‹": "é’©å­å¼è¿æ¥ï¼Œå¤šè§äºç¾ç³»å’Œéƒ¨åˆ†æ¬§ç³»è½¦å‹",
    "ä¾§æ’å¼": "ä»ä¾§é¢æ’å…¥çš„æ¥å¤´ï¼Œå¸¸è§äºé«˜ç«¯è½¦å‹"
}

cols = st.columns(4)
for idx, (connector_type, description) in enumerate(connector_info.items()):
    with cols[idx]:
        st.metric(connector_type, description)

# åº•éƒ¨ä¿¡æ¯
st.markdown("---")
st.markdown("""
**ä½¿ç”¨è¯´æ˜:**
1. åœ¨æœç´¢æ¡†ä¸­è¾“å…¥æ‚¨çš„è½¦å‹åç§°
2. ç³»ç»Ÿå°†æ˜¾ç¤ºåŒ¹é…çš„è½¦å‹åŠå…¶é›¨åˆ·è§„æ ¼
3. ç‚¹å‡»çƒ­é—¨è½¦å‹æŒ‰é’®å¯ä»¥å¿«é€Ÿæœç´¢

**æ³¨æ„äº‹é¡¹:**
- ä¸åŒå¹´ä»½çš„åŒæ¬¾è½¦å‹å¯èƒ½æœ‰ä¸åŒçš„é›¨åˆ·è§„æ ¼
- æœ¬æ•°æ®ä»…ä¾›å‚è€ƒï¼Œè¯·ä»¥å®é™…æµ‹é‡ä¸ºå‡†
- å¦‚æœ‰ç–‘é—®ï¼Œå»ºè®®å’¨è¯¢ä¸“ä¸šæ±½è½¦é…ä»¶åº—
""")
